#!/usr/bin/env python3
"""
Test script for EPOCH 4 incremental update functionality.

This demonstrates the complete incremental pipeline with:
- Change detection at the block level
- Content merging for existing entities
- Atomic commits for each update
- Living system behavior
"""

import logging
import sys
import shutil
from pathlib import Path
from unittest.mock import patch
import json
import tempfile
import time

# Mock the user input to automatically confirm bootstrap
def mock_confirm_bootstrap():
    """Mock function to automatically confirm bootstrap."""
    print("âš ï¸  BOOTSTRAP MODE (AUTO-CONFIRMED FOR TESTING)")
    print("Bootstrap mode will process all data from scratch...")
    return True

# Import after setting up the mock
import main
from kultivator.importers import LogseqEDNImporter
from kultivator.database import DatabaseManager
from kultivator.versioning import VersionManager
from kultivator.models import CanonicalBlock


def setup_logging():
    """Configure logging for the test."""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[logging.StreamHandler(sys.stdout)]
    )


def cleanup_test_files():
    """Clean up test files from previous runs."""
    paths_to_clean = [
        Path("wiki"),
        Path("kultivator.db"),
        Path("logseq_last_state.json"),
        Path("kultivator.log"),
        Path("test_logseq_data")
    ]
    
    for path in paths_to_clean:
        if path.exists():
            if path.is_dir():
                shutil.rmtree(path)
            else:
                path.unlink()
    
    print("Cleaned up test files")


def create_mock_logseq_data():
    """Create a mock Logseq data directory for testing."""
    test_data_dir = Path("test_logseq_data")
    test_data_dir.mkdir(exist_ok=True)
    
    # Create a simple JSON file to simulate Logseq data
    sample_data = [
        {
            "block/uuid": "test-block-1",
            "block/content": "Meeting with [[Sarah Wilson]] about [[Project Alpha]]",
            "block/page": "journals/2024_05_22.md"
        },
        {
            "block/uuid": "test-block-2", 
            "block/content": "[[TechCorp]] approved the budget for [[Cloud Migration]]",
            "block/page": "pages/work_notes.md"
        }
    ]
    
    # Write sample data file
    with open(test_data_dir / "sample.json", "w") as f:
        json.dump(sample_data, f, indent=2)
    
    return test_data_dir


def modify_mock_logseq_data():
    """Modify the mock Logseq data to simulate changes."""
    test_data_dir = Path("test_logseq_data")
    
    # Modified data with new information
    modified_data = [
        {
            "block/uuid": "test-block-1",
            "block/content": "Meeting with [[Sarah Wilson]] about [[Project Alpha]] - Budget approved for Q3",
            "block/page": "journals/2024_05_22.md"
        },
        {
            "block/uuid": "test-block-2", 
            "block/content": "[[TechCorp]] approved the budget for [[Cloud Migration]]",
            "block/page": "pages/work_notes.md"
        },
        {
            "block/uuid": "test-block-3",
            "block/content": "New team member [[David Chen]] joined the [[Project Alpha]] team",
            "block/page": "journals/2024_05_23.md"
        }
    ]
    
    # Write modified data
    with open(test_data_dir / "sample.json", "w") as f:
        json.dump(modified_data, f, indent=2)
    
    print("Modified mock Logseq data to simulate changes")


def test_change_detection():
    """Test the block-level change detection mechanism."""
    print("\n=== Testing Change Detection ===")
    
    try:
        # Create test data
        test_data_dir = create_mock_logseq_data()
        
        # Initialize importer
        importer = LogseqEDNImporter(str(test_data_dir))
        
        # First run - should detect all blocks as changed (no previous state)
        changed_blocks = importer.get_changed_blocks()
        
        if len(changed_blocks) > 0:
            print(f"âœ… Initial run: {len(changed_blocks)} blocks detected as changed")
        else:
            print("âŒ No blocks detected on initial run")
            return False
        
        # Second run - should detect no changes
        changed_blocks_2 = importer.get_changed_blocks()
        
        if len(changed_blocks_2) == 0:
            print("âœ… Second run: No changes detected (idempotent)")
        else:
            print(f"âŒ Second run detected {len(changed_blocks_2)} changes (should be 0)")
            return False
        
        # Modify data and test again
        modify_mock_logseq_data()
        changed_blocks_3 = importer.get_changed_blocks()
        
        if len(changed_blocks_3) > 0:
            print(f"âœ… After modification: {len(changed_blocks_3)} blocks detected as changed")
        else:
            print("âŒ No changes detected after modification")
            return False
        
        return True
        
    except Exception as e:
        print(f"âŒ Change detection test failed: {e}")
        return False


def test_bootstrap_then_incremental():
    """Test the complete bootstrap followed by incremental update workflow."""
    print("\n=== Testing Bootstrap + Incremental Workflow ===")
    
    try:
        # Create initial test data
        test_data_dir = create_mock_logseq_data()
        
        # Run bootstrap first
        print("ğŸš€ Running bootstrap...")
        with patch('main.confirm_bootstrap_wipe', side_effect=mock_confirm_bootstrap):
            main.run_bootstrap_pipeline("logseq", str(test_data_dir))
        
        # Check initial state
        with DatabaseManager() as db:
            initial_entities = len(db.list_entities())
        
        # Check Git state
        version_manager = VersionManager("wiki")
        if version_manager._is_git_repository():
            initial_commits = len(version_manager.get_commit_history())
            print(f"âœ… Bootstrap completed: {initial_entities} entities, {initial_commits} commits")
        else:
            print("âŒ Git repository not created during bootstrap")
            return False
        
        # Modify data to simulate changes
        print("ğŸ“ Modifying data to simulate changes...")
        modify_mock_logseq_data()
        
        # Run incremental update
        print("ğŸ”„ Running incremental update...")
        main.run_incremental_pipeline("logseq", str(test_data_dir))
        
        # Check final state
        with DatabaseManager() as db:
            final_entities = len(db.list_entities())
            
        final_commits = len(version_manager.get_commit_history())
        
        # Should have more entities and commits after incremental update
        if final_entities >= initial_entities and final_commits > initial_commits:
            print(f"âœ… Incremental update completed: {final_entities} entities (+{final_entities-initial_entities}), {final_commits} commits (+{final_commits-initial_commits})")
            return True
        else:
            print(f"âŒ Incremental update failed: {final_entities} entities, {final_commits} commits")
            return False
        
    except Exception as e:
        print(f"âŒ Bootstrap + Incremental test failed: {e}")
        return False


def test_no_changes_behavior():
    """Test that running incremental mode with no changes does nothing."""
    print("\n=== Testing No Changes Behavior ===")
    
    try:
        # Create test data
        test_data_dir = create_mock_logseq_data()
        
        # Run bootstrap
        with patch('main.confirm_bootstrap_wipe', side_effect=mock_confirm_bootstrap):
            main.run_bootstrap_pipeline("logseq", str(test_data_dir))
        
        # Get initial state
        version_manager = VersionManager("wiki")
        initial_commits = len(version_manager.get_commit_history())
        
        # Run incremental update without changes
        print("ğŸ”„ Running incremental update with no changes...")
        main.run_incremental_pipeline("logseq", str(test_data_dir))
        
        # Check that no new commits were created
        final_commits = len(version_manager.get_commit_history())
        
        if final_commits == initial_commits:
            print("âœ… No changes detected: No new commits created")
            return True
        else:
            print(f"âŒ Unexpected commits created: {final_commits} vs {initial_commits}")
            return False
            
    except Exception as e:
        print(f"âŒ No changes test failed: {e}")
        return False


def test_atomic_commits():
    """Test that atomic commits are created for each entity update."""
    print("\n=== Testing Atomic Commits ===")
    
    try:
        # Create test data
        test_data_dir = create_mock_logseq_data()
        
        # Run bootstrap
        with patch('main.confirm_bootstrap_wipe', side_effect=mock_confirm_bootstrap):
            main.run_bootstrap_pipeline("logseq", str(test_data_dir))
        
        # Get initial commit count
        version_manager = VersionManager("wiki")
        initial_commits = len(version_manager.get_commit_history())
        
        # Modify data to create multiple entities
        test_data_dir = Path("test_logseq_data")
        multi_entity_data = [
            {
                "block/uuid": "test-block-1",
                "block/content": "Meeting with [[Sarah Wilson]] about [[Project Alpha]] - Budget approved for Q3",
                "block/page": "journals/2024_05_22.md"
            },
            {
                "block/uuid": "test-block-4",
                "block/content": "[[New Company]] partnership with [[Another Project]]",
                "block/page": "pages/business.md"
            }
        ]
        
        with open(test_data_dir / "sample.json", "w") as f:
            json.dump(multi_entity_data, f, indent=2)
        
        # Run incremental update
        print("ğŸ”„ Running incremental update with multiple entities...")
        main.run_incremental_pipeline("logseq", str(test_data_dir))
        
        # Check commits
        final_commits = len(version_manager.get_commit_history())
        commit_increase = final_commits - initial_commits
        
        if commit_increase > 0:
            print(f"âœ… Atomic commits created: {commit_increase} new commits")
            
            # Show recent commits
            recent_commits = version_manager.get_commit_history(5)
            for commit in recent_commits[:3]:
                print(f"  ğŸ“ {commit['short_hash']}: {commit['message'][:50]}...")
            
            return True
        else:
            print("âŒ No atomic commits created")
            return False
            
    except Exception as e:
        print(f"âŒ Atomic commits test failed: {e}")
        return False


def test_wiki_content_updates():
    """Test that wiki content is properly updated with new information."""
    print("\n=== Testing Wiki Content Updates ===")
    
    try:
        # Create test data
        test_data_dir = create_mock_logseq_data()
        
        # Run bootstrap
        with patch('main.confirm_bootstrap_wipe', side_effect=mock_confirm_bootstrap):
            main.run_bootstrap_pipeline("logseq", str(test_data_dir))
        
        # Find a wiki file to examine
        wiki_dir = Path("wiki")
        wiki_files = list(wiki_dir.rglob("*.md"))
        
        if not wiki_files:
            print("âŒ No wiki files found after bootstrap")
            return False
            
        # Read initial content
        sample_file = wiki_files[0]
        with open(sample_file, 'r', encoding='utf-8') as f:
            initial_content = f.read()
        
        print(f"ğŸ“„ Examining {sample_file.name}")
        print(f"Initial content length: {len(initial_content)} characters")
        
        # Modify data
        modify_mock_logseq_data()
        
        # Run incremental update
        main.run_incremental_pipeline("logseq", str(test_data_dir))
        
        # Check if content was updated
        if sample_file.exists():
            with open(sample_file, 'r', encoding='utf-8') as f:
                updated_content = f.read()
            
            print(f"Updated content length: {len(updated_content)} characters")
            
            if updated_content != initial_content:
                print("âœ… Wiki content was updated")
                return True
            else:
                print("âš ï¸  Wiki content unchanged (may be expected if no relevant changes)")
                return True
        else:
            print("âŒ Wiki file disappeared after update")
            return False
            
    except Exception as e:
        print(f"âŒ Wiki content update test failed: {e}")
        return False


def run_tests():
    """Run all EPOCH 4 tests."""
    setup_logging()
    
    print("ğŸ§ª KULTIVATOR EPOCH 4 TEST SUITE")
    print("=" * 60)
    
    # Clean up before testing
    cleanup_test_files()
    
    # Run tests
    tests = [
        ("Change Detection", test_change_detection),
        ("Bootstrap + Incremental", test_bootstrap_then_incremental),
        ("No Changes Behavior", test_no_changes_behavior),
        ("Atomic Commits", test_atomic_commits),
        ("Wiki Content Updates", test_wiki_content_updates)
    ]
    
    passed = 0
    failed = 0
    
    for test_name, test_func in tests:
        print(f"\nğŸ” Running {test_name} test...")
        try:
            if test_func():
                print(f"âœ… {test_name} test PASSED")
                passed += 1
            else:
                print(f"âŒ {test_name} test FAILED")
                failed += 1
        except Exception as e:
            print(f"âŒ {test_name} test FAILED with exception: {e}")
            failed += 1
    
    # Final results
    print("\n" + "=" * 60)
    print(f"ğŸ¯ TEST RESULTS: {passed} passed, {failed} failed")
    print("=" * 60)
    
    if failed == 0:
        print("ğŸ‰ ALL TESTS PASSED!")
        print("\nEPOCH 4 Implementation is working correctly:")
        print("âœ… Block-level change detection")
        print("âœ… Incremental processing pipeline")
        print("âœ… Content merging for existing entities")
        print("âœ… Atomic commits for each update")
        print("âœ… Living system behavior")
        print("âœ… Efficient processing of only changed content")
    else:
        print(f"âŒ {failed} tests failed. Please check the implementation.")
        
    return failed == 0


if __name__ == "__main__":
    success = run_tests()
    sys.exit(0 if success else 1) 